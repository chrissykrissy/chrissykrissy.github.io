---
title : 사용자 수에 따른 규모 확장성
date: 2024-10-14 +1300
categories: [System Design]
tags: [interview-prep]
---
# Scale From Zero To Millions of Users

## Scale From Zero To Millions Of Users

### Single server setup

![Untitled](/assets/img/sysdesign/chapter1/Untitled.png)

1. User access websites through domain names.
2. IP address is returned to the browser or mobile app.
3. Once IP address is obtained, Hypertext Transfer Protocol (HTTP) requests are sent directly to the web server.
4. The web server returns HTML pages or JSON response for rendering.

Traffic Source

1) Web application

- server-side languages (Java, Python, etc) - handle business logic, storage
- client-side language (HTML, JavaScript) - for presentation

2) Mobile application

- HTTP protocol = communication protocol btwn mobile app - web server
- JSON = common API response format to transfer data

### Database

With growth, need multiple servers (web/mobile, db) → scaled independently

![Untitled](/assets/img/sysdesign/chapter1/Untitled%201.png)

### Which db to use?

Relational database management system (RDBMS)/SQL

ex) MySQL, Oracle, PostgreSQL

- represent and store data in table and rows
- perform join across different db tables

Non-Relational databases/NoSQL

ex) CouchDB, Cassandra, HBase, Amazon DynamoDB

- grouped into four categories
    - k-v stores
    - graph stores
    - column stores
    - document stores
- join operations are generally NOT supported
- right choice if:
    - application requires super-low latency
    - data are unconstructed/don’t have any relational data
    - only need to serialize and deserialize data (JSON, XML, YAML)
    - need to store a massive amount of data

### Vertical scaling vs. horizontal scaling

Vertical scaling = “scale up”

- process of adding more power (CPU, RAM, etc.) to your servers
- simple and great option when traffic is low
- limitations:
    - has a hard limit (impossible to add unlimited CPU and memory to a single server)
    - does not have failover and redundancy
        - if one server goes down, the web/app goes down with it completely

Horizontal scaling = “scale out”

- scale by adding more servers into pool of resources
- more desirable for large scale applications

### Load balancer

: Evenly distributes incoming traffic among web servers that are defined in a load-balanced set

Best used :

- when users are unable to access the website due to it being offline
- when too many users access the web server simultaneously and reaches the web server’s load limit
    - users experience slower response or fail to connect

![Untitled](/assets/img/sysdesign/chapter1/Untitled%202.png)

With load balancer

- user connect to the public IP of the load balancer directly
    - web servers are unreachable directly by clients
        - load balancer communicates with web servers through private IPs
    - for security, private IPs are used for communication between servers
        - private IP = IP address reachable only between servers in the same network but unreachable over the internet
- and with a second web server → solve no failover and improve the availability of the web tier
    - if server 1 down, all traffic routed to server 2
    - if traffic grows rapidly and two servers are not enough to handle → add more servers to the web server pool and load balancer distributes the requests

Q. What about the data tier? Currently no support for failover and redundancy. 

### Database replication

Master(original) - Slave(copies) relationships

- Master db generally only supports write operations
- Slave db gets copies of the db from the master db only and only supports read operations
- All data-modifying commands must be sent to the master db

Most applications require much higher ratio of reads to writes (as shown below) → #master < #slaves

![Untitled](/assets/img/sysdesign/chapter1/Untitled%203.png)

Advantages of db replication :

- Better performance : bc allows more queries to be processed in parallel
    - all writes & updates = master nodes
    - read operations = distributed across slave nodes
- Reliability : data is preserved and no need to worry about data loss since it is replicated across multiple locations
- High availability : website remains in operation even if a db is down

What if one of db goes offline?

- if only one slave db available and goes offline, read operations are directed to the master temporarily
- if master goes offline, a slave db will be promoted to the new master
    - in production systems, promoting a new master is more complicated as the data in the slave db might not be up to date
        - missing data needs to be updated by running data recovery scripts

![Untitled](/assets/img/sysdesign/chapter1/Untitled%204.png)

- A user gets the IP address of the load balancer from DNS.
- A user connects the load balancer with this IP address.
- The HTTP request is routed to either Server 1 or Server 2.
- A web server reads user data from a slave database.
- A web server routes any data-modifying operations to the master database. This includes write, update, and delete operations.

Improve load/response time

- by adding a cache layer
- by shifting static content to the content delivery network (CDN)

### Cache

: temporary storage area that stores the result of expensive responses or frequently accessed data in memory → quicker response to requests

### Cache tier

: temporary data store layer, faster than the db

- better system performance, reduce db workloads, ability to scale the cache tier independently

![Untitled](/assets/img/sysdesign/chapter1/Untitled%205.png)

→ read-through cache

### Considerations for using cache

- Use when data is read frequently but modified infrequently
    - cache X ideal for persisting data
- Expiration policy
- Consistency = keeping the data store and the cache in sync
    - data-modifying operations on data store and cache are not in a single transaction
- Mitigating failures
    - Single cache server = potential single point of failure(SPOF)
    - Multiple cache servers across different data centers are recommended
    - Or, over provision the required memory by certain percentage
        - buffer as the memory usage increases
- Eviction policy
    - once cache is full, any request to add item may cause existing items to be removed
        - Least-recently-used (LRU) = most popular
        - Least frequently used (LFU)
        - First in first out (FIFO)

### Content delivery network (CDN)

: net work of geographically dispersed servers used to deliver static content (images, videos, CSS, JavaScript files, etc.)

*Dynamic content caching*

- *enables the caching of HTML pages that are based on request path, query strings, cookies, and request headers*

How CDN works at a high level

- when a user visits a website, a CDN server closest to the user will deliver static content
    - ex) CDN in SF, LA user get content faster than Europe users

![Untitled](/assets/img/sysdesign/chapter1/Untitled%206.png)

![Untitled](/assets/img/sysdesign/chapter1/Untitled%207.png)

1. User A tries to get image.png by using an image URL. The URL’s domain is provided by the CDN provider. The following two image URLs are samples used to demonstrate what image URLs look like on Amazon and Akamai CDNs:

- `https://mysite.cloudfront.net/logo.jpg`
- `https://mysite.akamai.com/image-manager/img/logo.jpg`

2. If the CDN server does not have image.png in the cache, the CDN server requests the file from the origin, which can be a web server or online storage like Amazon S3.

3. The origin returns image.png to the CDN server, which includes optional HTTP header Time-to-Live (TTL) which describes how long the image is cached.

4. The CDN caches the image and returns it to User A. The image remains cached in the CDN until the TTL expires.

5. User B sends a request to get the same image.

6. The image is returned from the cache as long as the TTL has not expired.

### Considerations of using a CDN

- Cost : CNDs run by third-party providers
- Setting appropriate cache expiry
- CDN fallback : how web/app copes with CDN failures
    - should be able to detect and request resources from the origin
- Invalidating files through 1) APIs by CDN vendors 2) object versioning

![Untitled](/assets/img/sysdesign/chapter1/Untitled%208.png)

1. Static assets (JS, CSS, images, etc.,) are no longer served by web servers. They are fetched from the CDN for better performance.
2. The database load is lightened by caching data.

### Stateless web tier

- scaling the web tier horizontally by store by moving the state out of the web tier → store session data in the persistent storage (RDBMS, or NoSQL)
    - each web server in the cluster can access state data from db

### Stateful architecture

![Untitled](/assets/img/sysdesign/chapter1/Untitled%209.png)

Problem : to authenticate a certain user, HTTP requests must be routed to the server that has the session information

- Adding/removing servers more difficult
- challenging to handle server failures

### Stateless architecture

![Untitled](/assets/img/sysdesign/chapter1/Untitled%2010.png)

HTTP requests from users can be sent to any web servers, which fetch state data from shared data store → simpler, more robust, and scalable

![Untitled](/assets/img/sysdesign/chapter1/Untitled%2011.png)

NoSQL data store → easy to scale

After state data is removed out of web servers, auto-scaling of the web tier is easily achieved by adding or removing servers based on traffic load.

### Data centers

: needed to improve availability and provide a better user experience across wider geo areas 

Users are geo-routed

![Untitled](/assets/img/sysdesign/chapter1/Untitled%2012.png)

In case of significant data center outage, direct to healthy data center

![Untitled](/assets/img/sysdesign/chapter1/Untitled%2013.png)

Technical challenges to resolve to achieve multiple data center setup :

- Traffic redirection such as GeoDNS
- Data synchronization
    - In failover cases, replicate data across multiple data centers
- Test and deployment
    - important to test website/app at different locations
    - automated deployment tools are vital to keep services consistent through all the data centers

### Message queue

: key strategy employed by many real-world distributed systems to solve the need to decouple different components of the system so they can be scaled independently

: durable component stored in memory that supports async communication

- serves as a buffer and distributes async requests

Basic architecture

- input services (producers/publishers) create messages and publish them to a message queue
- services/servers (consumers/subscribers) connect to the queue, and perform actions defined by the messages

![Untitled](/assets/img/sysdesign/chapter1/Untitled%2014.png)

→ Decoupling producer and consumer

- can be scaled independently

### Logging, metrics, automation

Logging : monitor error logs either at per server level or use tools to aggregate to a centralized service

Metrics : collecting different types of metrics help gain business insights and understand the health status of the system

- host level metrics : CPU, Memory, disk I/O..
- aggregated level metrics : performance of the entire db tier, cache tier..
- key business metrics : daily active users, retention, revenue..

Automation : improve productivity by practicing continuous integration/continuous deployment

![Untitled](/assets/img/sysdesign/chapter1/Untitled%2015.png)

### Database scaling

Vertical scaling

Drawbacks : 

- can add CPU, RAM.. but hardware limits exist
- greater risk of SPOF
- cost

Horizontal scaling = sharding

![Untitled](/assets/img/sysdesign/chapter1/Untitled%2016.png)

- separates large dbs into smaller parts called shards
    - each shard shares the same schema but actual data is unique to the shard
    
    ![Untitled](/assets/img/sysdesign/chapter1/Untitled%2017.png)
    
    ![Untitled](/assets/img/sysdesign/chapter1/Untitled%2018.png)
    

Sharding key (partition key)

- determine how data is distributed
- allows to retrieve and modify data efficiently by routing db queries to the correct db
- needs to evenly distribute data

Complexities :

- Resharding data : needed when 1) single shard could no longer hold more data due to rapid growth 2) certain shards experience shard exhaustion faster than others due to uneven data distribution
    - requires updating the sharding function and moving data around
    - consistent hashing is common technique to solve
- Celebrity problem (hotspot key problem) : excessive access to a specific shard could cause server overload
    - need to allocate a shard for each celebrity (further partition)
- Join and de-normalization : hard to perform join operations across db shards
    - denomalize the db so that queries can be performed in a single table
    
    ![Untitled](/assets/img/sysdesign/chapter1/Untitled%2019.png)
    
    ### Millions of users and beyond
    
    How we scale our system
    
    - Keep web tier stateless
    - Build redundancy at every tier
    - Cache data as much as you can
    - Support multiple data centers
    - Host static assets in CDN
    - Scale your data tier by sharding
    - Split tiers into individual services
    - Monitor your system and use automation tools