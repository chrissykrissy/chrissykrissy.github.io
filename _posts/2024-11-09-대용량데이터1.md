---
title : 대용량 데이터 처리
date: 2024-11-09 +2000
categories: [Big Data Processing]
tags: [big-data, interview-prep]
---

# 대용량 데이터를 효율적으로 처리하기 위한 기초 지식

## 빅데이터란?
> 보통의 데이터베이스 소프트웨어로는 수집, 저장, 관리, 분석이 어려울 정도로 많은 데이터

- 처음부터 빅데이터가 아니더라도, 쌓이다 보면 빅 데이터가 되는 경우가 대반사
  - 실시간 vs. 정적

## 대용량 데이터를 관리하는 방법

### 샤딩
> 대량의 DB데이터를 다른 물리 시스템에 분할하여 저장하는 기술

- 즉, 많은 데이터들이 저장되어 있는 DB를 반으로 쪼개서 관리
- 각 DB에 저장되어 있는 데이터들이 분할 되고 그만큼 저장공간 확보 + 조회성 쿼리 빠르게 개선
![img](/assets/img/big-data/image.png)

- 단, 데이터 베이스 서버를 하나 더 구축한다는 것은 그만큼 비용이 든다는 것을 의미

### 파티셔닝
> 대량의 데이터 테이블을 테이블 분할 통해 저장하는 기술

![img](/assets/img/big-data/image%20copy.png)
- 한 테이블 내에 굉장히 많은 데이터가 있다면 쪼개는 방식

#### 수평 파티셔닝
- 레코드를 기준으로 분할하여 특정 범위만 조회하여 성능을 개선하는 기법 (샤딩과 동일한 개념)
- 장점 : 테이블당 데이터 개수가 작아지고 따라서 Index 개수도 작아져 성능이 향상된다.
- 단점 : 테이블간 join 연산이 증가해 조회성 시간이 증가 될 수도 있다.

#### 수직 파티셔닝
- 테이블의 모든 컬럼 중 특정 컬럼을 쪼개서 별도 저장하는 형태, 하나의 엔티티를 2개 이상으로 분리
- 장점 : 자주 사용하는 컬럼을 분리하여 성능이 향상, 컬럼 수가 축소 됨으로 디스크 I/O 이점
- 단점 : 파티션 키 값 변경에 대한 별도 관리 필요

### 인덱스
> 데이터가 많은 테이블들에 대해서 빠르게 소수의 데이터를 찾고 싶을때 사용하는 색인 방법

- 장점 : SELECT문을 이용하여 검색하는 속도가 빠름. 단, 찾으려는 데이터가 전체 데이터의 소수여야 함
- 단점 : 인덱스를 저장할 수 있는 테이블을 별도로 선언해야 함. 따라서 추가적인 공간이 필요. SELECT 문이 아닌 변경작업이 빈번하면 오히려 성능이 나빠짐.

### 클러스터형 인덱스
> 테이블의 레코드를 비슷한것 (프라이머리 키를 기준)끼리 묶어서 저장하는 형태

- 프라이머리 키 값에 의해 레코드의 저장 위치가 결정됨. 데이터의 프라이머리 키 값이 변경되면 데이터 파일에 위치한 저장 위치도 변경. 
- 클러스터형 인덱스는 테이블의 데이터가 인덱스의 순서대로 물리적인 디스크에 저장되는 방식
![img](/assets/img/big-data/image%20copy%202.png)


### 논 클러스터형 인덱스
> 인덱스와 데이터가 별도의 위치에 저장됨
- 데이터 레코드의 순서가 인덱스 엔트리 순서와 관계없이 저장됨

#### 클러스터 vs. 논클러스터 인덱스 차이
[상황1] 이름으로 정리
- 클 : 자료들을 이름 순으로 순서대로 정리
- 논클 : 현재 자료에서 각 이름이 어디에 위치해 있는지 따로 저장

[상황2] 이름으로 찾기
- 클 : 순서대로 정리되어 있어서 빠르게 전달
- 논클 : 해당 이름이 적혀있는 위치를 확인한 뒤에 자료를 찾고 전달
  
> 단일 조건일 경우 클러스터 인덱스가 훨씬 빠름

[상황3] 이름을 추가하여 정리 요청
- 클 : 정렬된 자료에 추가 위치를 파악한 뒤 공간을 만들어서 추가 + 재정렬
- 논클 : 자료를 추가하고 따로 추가된 자료 위치를 기록

[상황4] 나이도 찾기 편리하게 정리 요청
- 클 : 이미 이름으로 정렬되어 있기 때문에, 기존 형태를 유지할 수 없음
- 논클 : 나이 관련 위치를 따로 기록

> 논 클러스터형 인덱스는 데이터 조회에 대해서 느린 성능을 보이지만, 변경이 빠르고 한 테이블당 다수의 인덱스를 생성할 수 있다는 장점이 있음

## 그 외
- Reader 개선
  - Chunk processing
  - Pagination
    - 단, limit offset 부담 -> queryDsl 을 사용하여 offset 이 항상 0일 수 있도록 처리
- Aggregation 개선
    - Join + GroupBy + Sum
      - 연산과정이 쿼리에 의존적
      - 쿼리 튜닝 난이도 상
      - 튜닝을 위한 과도한 인덱스 추가
    - 레디스를 사용해서 GroupBy는 포기하고 직접 Aggregate
      - 연산은 빠르나, 네트워크 IO를 고려해야함
- Writer 개선
  - JDBC Batch insert 사용

> 즉, 모든 부분을 빅데이터를 위해 optimize 해야함

# 데이터 처리를 위한 Mock data generation
## 데이터 스키마 정의
```
1. id           - INT           - 4 bytes
2. name         - VARCHAR(50)   - 평균 30 bytes
3. email        - VARCHAR(100)  - 평균 50 bytes
4. address      - VARCHAR(255)  - 평균 100 bytes
5. phone_number - VARCHAR(15)   - 15 bytes
6. age          - INT           - 4 bytes
7. created_at   - DATETIME      - 8 bytes
8. updated_at   - DATETIME      - 8 bytes
9. status       - VARCHAR(10)   - 평균 5 bytes
10. notes       - TEXT          - 평균 200 bytes
```
총 건당 데이터 크기 = 4 + 30 + 50 + 100 + 15 + 4 + 8 + 8 + 5 + 200 = ```424 bytes```

## 예상 데이터 용량 산정
N건의 데이터 총 크기 = N * 건당 데이터
```
1억건 * 424bytes = 약 42.4GB
```

## Mock Data Generation
Python Faker 라이브러리를 사용하면 다양한 랜덤 데이터 생성가능
```python
from faker import Faker
import pymysql

fake = Faker()
conn = pymysql.connect(host='localhost', user='user', password='passwd', db='database')

with conn.cursor() as cursor:
    for _ in range(100000000):  # 예: 1억 건
        sql = "INSERT INTO users (id, name, email, address, phone_number, age, created_at, updated_at, status, notes) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)"
        cursor.execute(sql, (None, fake.name(), fake.email(), fake.address(), fake.phone_number(), fake.random_int(min=18, max=90), fake.date_time(), fake.date_time(), fake.random_element(elements=('active', 'inactive')), fake.text()))
    conn.commit()
conn.close()
```


# 대용량 데이터 사용 환경 시뮬레이션을 위한 상황 or Business
- Batch Applications
  - 특정 시간에 많은 데이터를 일괄처리
  - ex) 상품 주문 배송정보를 일괄 전송

참고
- https://boomrabbit.tistory.com/260 
- https://www.youtube.com/watch?v=2IIwQDIi3ys&ab_channel=%EC%B9%B4%EC%B9%B4%EC%98%A4 